{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW1_question.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mqaKsJ1aQfQb","colab_type":"text"},"source":["# Deep Learning - **Homework #1**\n","\n","* Teching assistant email: trung@uef.fi\n","* Deadline: **23:59 - 14/12/2019 (UPDATED)**\n","* Maximum: **3 points**\n","\n","Goals:\n","\n","* Basic Machine Learning understanding\n","* Perceptron algorithm\n","* Multi-layer Adaline algorithm\n","\n","References:\n","\n","1. Jean-Christophe B. Loiseau, 2019. [Rosenblattâ€™s perceptron, the first modern neural network][ref_1]. Towards Data Science, Medium.\n","\n","How to submit:\n","\n","* Option#1: **File** $\\to$ **Download .ipynb** $\\to$ _Send to .ipynb file to my email, or submit it to moodle page_.\n","* Option#2: **Share** read-only notebook link to my email.\n","* _If you choose to share the notebook, please re-name the notebook to your student name and student number, I will take the snapshot of your notebook before the deadline, any modification afterward will be disregarded._\n","\n","**NOTE**: This is official homework and will be graded\n","\n","[ref_1]: https://towardsdatascience.com/rosenblatts-perceptron-the-very-first-neural-network-37a3ec09038a"]},{"cell_type":"code","metadata":{"id":"A-a_YgqAvfW-","colab_type":"code","outputId":"a4395b3a-b927-4909-9c6e-da2bfc67f076","executionInfo":{"status":"ok","timestamp":1572598860006,"user_tz":-120,"elapsed":2454,"user":{"displayName":"Trung Ngo Trong","photoUrl":"https://lh6.googleusercontent.com/-UPh16zdAKSc/AAAAAAAAAAI/AAAAAAAALNU/yTwmj56NWg8/s64/photo.jpg","userId":"17725701072863810182"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# All libraries we use for this HW, run this block first!\n","%tensorflow_version 2.x\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","from sklearn.datasets import load_linnerud\n","from sklearn.linear_model import LinearRegression\n","from sklearn.cluster import KMeans\n","np.random.seed(8)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wnqt-kT7j7DG","colab_type":"text"},"source":["# Question 1\n","Run and read the following code blocks and answer following questions:\n","\n","1.   Which learning scheme is used (i.e. supervised, unsupervised or reinforcment learning)?\n","2.   How do we interpret the results? \n","3.   Are they good results, if not, what wrong with them?\n","\n","**NOTE**: you have to three above questions for both _a)_ and _b)_\n"]},{"cell_type":"markdown","metadata":{"id":"DnpLL3Rrkskl","colab_type":"text"},"source":["### **a)** First block"]},{"cell_type":"code","metadata":{"id":"st8-np7Lkvm6","colab_type":"code","colab":{}},"source":["# Description of the dataset\n","# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_linnerud.html#sklearn.datasets.load_linnerud\n","data = load_linnerud()\n","X = data.data[:, :2]  # only take first 2 features\n","y = data.target[:, 0]  # only take first target\n","print(\"Features name:\", data.feature_names[:2])\n","print(\"Target name  :\", data.target_names[0])\n","\n","model = LinearRegression()\n","model.fit(X, y)\n","y_pred = model.predict(X)\n","\n","\n","def plot_helper(chins, situps, weight, prediction):\n","  plt.figure(figsize=(12, 5))\n","  ax = plt.subplot(1, 2, 1)\n","  sns.scatterplot(x=\"Chins\",\n","                  y=\"Situps\",\n","                  size='Weight',\n","                  data=pd.DataFrame({\n","                      'Chins': chins,\n","                      'Situps': situps,\n","                      'Weight': weight\n","                  }),\n","                  ax=ax)\n","  ax = plt.subplot(1, 2, 2)\n","  sns.scatterplot(x=\"Chins\",\n","                  y=\"Situps\",\n","                  size='Prediction',\n","                  data=pd.DataFrame({\n","                      'Chins': chins,\n","                      'Situps': situps,\n","                      'Prediction': prediction\n","                  }),\n","                  ax=ax)\n","\n","plot_helper(chins=X[:, 0], situps=X[:, 1], weight=y, prediction=y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ILDralqSkwwS","colab_type":"text"},"source":["### **b)** Second block"]},{"cell_type":"code","metadata":{"id":"6TO1WLqFkyma","colab_type":"code","colab":{}},"source":["# We use the same dataset in a)\n","model = KMeans(2)\n","model.fit(X)\n","y_pred = model.predict(X)\n","\n","sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y_pred)\n","plt.xlabel('Chins')\n","plt.ylabel(\"Situps\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vv3ySMM0k1QQ","colab_type":"text"},"source":["# Question 2\n","\n","### **a)** Filling in `TODO` of following code block to: _Create perceptron and use it to solve an AND classification problem_\n","\n","Calculating the output of perceptron:\n","\n","$y= \\mathrm{F} \\big( \\sum_{i=0}^D w_i \\cdot x_i \\tag{1} \\big)$\n","\n","where $x_0=1$, $D$ is the number of input features, and $\\mathrm{F}(.)$ is the threshold function, i.e.\n","\n","$\\mathrm{F}(x) =\n","  \\begin{cases}\n","    1       & \\quad \\text{if } x \\geq \\mathrm{THRESHOLD}\\\\\n","    0  & \\quad \\text{if } x < \\mathrm{THRESHOLD}\n","  \\end{cases}$\n","\n","The learning algorithm of perceptron following this update equation:\n","\n","$w_i = w_i - \\lambda \\cdot \\frac{1}{N} \\sum_{j=0}^N(\\bar{y}^{(j)} - y^{(j)}) x^{(j)}_i \\tag{2}$\n","\n","where $N$ is the total number of training examples, $\\bar{y}$ is the predicted value of $y$ (the target variable), $(j)$ is the index of an example, and $\\lambda$ is the learning rate.\n","\n","For more detail [[1]][ref_1]\n","\n","[ref_1]: https://towardsdatascience.com/rosenblatts-perceptron-the-very-first-neural-network-37a3ec09038a"]},{"cell_type":"code","metadata":{"id":"RG39nxRaxxOQ","colab_type":"code","outputId":"a449812e-fc28-4b99-e846-625114b5323c","executionInfo":{"status":"ok","timestamp":1572562642308,"user_tz":-120,"elapsed":2444,"user":{"displayName":"Trung Ngo Trong","photoUrl":"https://lh6.googleusercontent.com/-UPh16zdAKSc/AAAAAAAAAAI/AAAAAAAALNU/yTwmj56NWg8/s64/photo.jpg","userId":"17725701072863810182"}},"colab":{"base_uri":"https://localhost:8080/","height":459}},"source":["# Number of training iterations\n","NUM_ITERATIONS = 25\n","# Threshold for 0/1 classification\n","THRESHOLD = 0.5\n","# Learning rate\n","LEARNING_RATE = 1e6\n","\n","X = np.array(\n","    [[0, 0],\n","     [0, 1],\n","     [1, 0],\n","     [1, 1]]\n",")\n","# TODO: fill appropriate value for y\n","y = \n","\n","# Create perceptron weights (random weights)\n","weights = np.random.randn(2)\n","\n","# Train perceptron\n","for iteration in range(NUM_ITERATIONS):\n","  # TODO: Calculate predictions with current weights (Equation (1))\n","  predictions = \n","\n","  # Calculate accuracy (not needed for training, but to track the learning progress)\n","  accuracy = np.mean(predictions == y)\n","  # Print the accuracy\n","  print(\"Iteration %d: Acc %f \\t %s\" % (iteration, accuracy, str(predictions)))\n","\n","  # TODO: Update weights according to update rule (Equation (2))\n","  weights = \n","\n","# Print weights for inspection\n","print(weights)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Iteration 0: Acc 0.750000 \t [0 0 0 0]\n","Iteration 1: Acc 0.250000 \t [1 1 1 1]\n","Iteration 2: Acc 0.750000 \t [0 0 0 0]\n","Iteration 3: Acc 1.000000 \t [0 0 0 1]\n","Iteration 4: Acc 1.000000 \t [0 0 0 1]\n","Iteration 5: Acc 1.000000 \t [0 0 0 1]\n","Iteration 6: Acc 1.000000 \t [0 0 0 1]\n","Iteration 7: Acc 1.000000 \t [0 0 0 1]\n","Iteration 8: Acc 1.000000 \t [0 0 0 1]\n","Iteration 9: Acc 1.000000 \t [0 0 0 1]\n","Iteration 10: Acc 1.000000 \t [0 0 0 1]\n","Iteration 11: Acc 1.000000 \t [0 0 0 1]\n","Iteration 12: Acc 1.000000 \t [0 0 0 1]\n","Iteration 13: Acc 1.000000 \t [0 0 0 1]\n","Iteration 14: Acc 1.000000 \t [0 0 0 1]\n","Iteration 15: Acc 1.000000 \t [0 0 0 1]\n","Iteration 16: Acc 1.000000 \t [0 0 0 1]\n","Iteration 17: Acc 1.000000 \t [0 0 0 1]\n","Iteration 18: Acc 1.000000 \t [0 0 0 1]\n","Iteration 19: Acc 1.000000 \t [0 0 0 1]\n","Iteration 20: Acc 1.000000 \t [0 0 0 1]\n","Iteration 21: Acc 1.000000 \t [0 0 0 1]\n","Iteration 22: Acc 1.000000 \t [0 0 0 1]\n","Iteration 23: Acc 1.000000 \t [0 0 0 1]\n","Iteration 24: Acc 1.000000 \t [0 0 0 1]\n","[ 250000.02080584  250000.67970345 -250000.77850232]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t88g_1g8ybQR","colab_type":"text"},"source":["### **b)** In theory the perceptron algorithm should be able to solve the `AND` classification problem (i.e. give 100% accuracy). What is missing from above procedure? Could you make it work?"]},{"cell_type":"markdown","metadata":{"id":"c9Ds3xzLk9oH","colab_type":"text"},"source":["# Question 3\n","\n","Create multi-layer Adaline in `pytorch` or `tensorflow` (you only need to do **a)** or **b)** part of this question)\n","\n","Approximation Error for Adaline is given by:\n","\n","$E = \\frac{1}{2} (\\bar{y} - y)^2 \\tag{3}$\n","\n","where $\\bar{y}$ is the predicted value of $y$ (the target variable)\n","\n","Your tasks are divided into 2 steps:\n","\n","1. First filling in the `TODO`, create a multi-layer Adaline, and make the algorithm running\n","2. Modifying the training procedure to get reasonable better results.\n","\n","We will use the `linnerud` dataset from `Question 1` as training data"]},{"cell_type":"code","metadata":{"id":"tGLi29U-6dG6","colab_type":"code","outputId":"8d1de97d-24a7-4036-cb58-05655bc26231","executionInfo":{"status":"ok","timestamp":1572562642309,"user_tz":-120,"elapsed":2436,"user":{"displayName":"Trung Ngo Trong","photoUrl":"https://lh6.googleusercontent.com/-UPh16zdAKSc/AAAAAAAAAAI/AAAAAAAALNU/yTwmj56NWg8/s64/photo.jpg","userId":"17725701072863810182"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["X = data.data  # take all features\n","y = data.target[:, 0]  # only take first target\n","print(\"Features name:\", data.feature_names)\n","print(\"Target name  :\", data.target_names[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Features name: ['Chins', 'Situps', 'Jumps']\n","Target name  : Weight\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LpaJ-c1n6009","colab_type":"text"},"source":["### a) Multi-layer Adaline with `pytorch`\n","\n","Documnentation for `pytorch` neural network modules:\n","\n","https://pytorch.org/docs/stable/nn.html"]},{"cell_type":"code","metadata":{"id":"2Z7fVi966ycP","colab_type":"code","colab":{}},"source":["import torch\n","\n","# convert data to pytorch tensor\n","X_pt = torch.from_numpy(X.astype('float32'))\n","y_pt = torch.from_numpy(y.astype('float32'))\n","\n","# TODO: modify this single-layer Adaline into multi-layer adaline\n","network = torch.nn.Linear(X.shape[1], 1)\n","\n","def approximation_error(y_pred, y_true):\n","  # TODO: finish this function and return the approximation error of Adaline (Equation 3)\n","  pass\n","\n","# create Gradient descent optimizer\n","optimizer = torch.optim.SGD(network.parameters(), lr=0.01)\n","\n","# iterate for 25 epochs\n","for i in range(25):\n","  # zero the parameter gradients\n","  optimizer.zero_grad()\n","\n","  # forward + backward + optimize\n","  y_pred = network(X_pt)\n","  loss = approximation_error(y_pred, y_pt).mean()\n","  loss.backward()\n","  optimizer.step()\n","  \n","  # Print out error for monitoring\n","  print(\"Epoch %-3d\" % i, \"Error: \", loss.detach().numpy())\n","\n","# Evaluate our final prediction\n","y_pred = network(X_pt).detach().numpy()\n","plot_helper(chins=X[:, 0], situps=X[:, 1], weight=y, prediction=y_pred.ravel())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qDyx4RlB_giH","colab_type":"text"},"source":["### b) Multi-layer Adaline with `tensorflow`\n","\n","Documentation for `tensorflow` and `keras` for neural network:\n","\n","https://www.tensorflow.org/guide/keras/overview"]},{"cell_type":"code","metadata":{"id":"TPFuvgII_fFW","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","\n","# TODO: modify this single-layer Adaline into multi-layer adaline\n","network = keras.layers.Dense(1)\n","\n","def approximation_error(y_pred, y_true):\n","  # TODO: finish this function and return the approximation error of Adaline (Equation 3)\n","  pass\n","\n","# create Gradient descent optimizer\n","optimizer = keras.optimizers.SGD(lr=0.01)\n","\n","# iterate for 25 epochs\n","for i in range(25):\n","  # forward\n","  with tf.GradientTape() as tape:\n","    y_pred = network(X)\n","    loss = tf.reduce_mean(approximation_error(y_pred, y))\n","  # backward\n","  gradients = tape.gradient(loss, network.trainable_variables)\n","  # optimize\n","  optimizer.apply_gradients(zip(gradients, network.trainable_variables))\n","\n","  # Print out error for monitoring\n","  print(\"Epoch %-3d\" % i, \"Error: \", loss.numpy())\n","\n","# Evaluate our final prediction\n","y_pred = network(X).numpy()\n","plot_helper(chins=X[:, 0], situps=X[:, 1], weight=y, prediction=y_pred.ravel())"],"execution_count":0,"outputs":[]}]}